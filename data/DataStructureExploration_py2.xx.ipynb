{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "data_path = '/home/jovyan/work/LEAP/leap/regression/dataset1'\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extracts',\n",
       " 'dataset1-Copy1.bed',\n",
       " 'dataset1.bed',\n",
       " 'dataset1.cov',\n",
       " '.pversion',\n",
       " 'dataset1.bim',\n",
       " 'dataset1.fam',\n",
       " 'dataset1.phe.liab',\n",
       " 'dataset1.phe']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysnptools\n",
      "  Downloading pysnptools-0.3.9.zip (225kB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy>=0.15.1 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pysnptools)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.9.2 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pysnptools)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pandas>=0.16.2 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pysnptools)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /opt/conda/envs/python2/lib/python2.7/site-packages (from pandas>=0.16.2->pysnptools)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz>=2011k in /opt/conda/envs/python2/lib/python2.7/site-packages (from pandas>=0.16.2->pysnptools)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /opt/conda/envs/python2/lib/python2.7/site-packages (from python-dateutil->pandas>=0.16.2->pysnptools)\n",
      "Building wheels for collected packages: pysnptools\n",
      "  Running setup.py bdist_wheel for pysnptools: started\n",
      "  Running setup.py bdist_wheel for pysnptools: finished with status 'done'\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/67/3f/0a/2d16f1dca863803132f2fd208c928d6c388d4d0161bd8a94f9\n",
      "Successfully built pysnptools\n",
      "Installing collected packages: pysnptools\n",
      "Successfully installed pysnptools-0.3.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.0.3, however version 8.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.main(['install', 'pysnptools'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pysnptools.snpreader.bed import Bed\n",
    "import pysnptools.util as pstutil\n",
    "import pysnptools.util.pheno as phenoUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a grip on bed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fam file dataset1.fam\n",
      "Loading bim file dataset1.bim\n",
      "bed file is open dataset1.bed\n"
     ]
    }
   ],
   "source": [
    "bfile = 'dataset1'\n",
    "phenoFile = bfile+'.phe'\n",
    "chromosomes = xrange(1,11)\n",
    "prevalence = 0.001\n",
    "bed = Bed(bfile).read().standardize()\n",
    "causalSNPs = [s for s in bed.sid if 'csnp' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['csnp18', 'csnp35', 'csnp59', 'csnp78', 'csnp85'], \n",
       "      dtype='|S8')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed.sid[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['FAM1', 'person1'],\n",
       "       ['FAM1', 'person2'],\n",
       "       ['FAM1', 'person3'],\n",
       "       ..., \n",
       "       ['FAM1', 'person998'],\n",
       "       ['FAM1', 'person999'],\n",
       "       ['FAM1', 'person1000']], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed.iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed matrix shape: (1000, 10499)\n",
      "Size of bed matrix:   80mb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.02560486, -0.27215848, -0.95610942,  1.02534931, -1.51981533,\n",
       "       -1.30964838,  0.63613624, -0.63517447,  0.57405621, -0.260105  ,\n",
       "        0.83680296, -0.29262899,  0.81886119,  0.8546494 ,  0.98413493,\n",
       "        0.68009803, -0.25883879,  0.41862282, -1.75595071, -0.35218036,\n",
       "       -0.62280452,  0.37323019, -1.85210593,  0.38161617, -0.47674932,\n",
       "        1.04471355,  0.409157  ,  1.25615244, -1.00629693,  0.32462797,\n",
       "        0.51189572,  0.97311501, -1.07204019,  1.19379955,  0.8073641 ,\n",
       "        0.96046928,  0.35903931, -0.12674527, -0.55584135, -1.60930407,\n",
       "        0.60472281, -1.70265594,  0.40542603,  0.37102079,  0.47297522,\n",
       "        1.29137371,  1.26291616,  1.31811137, -0.50942098,  0.3869888 ,\n",
       "        0.76623177,  1.2044326 ,  1.31310913,  0.89309116, -0.98461312,\n",
       "        0.80937703, -0.11675322, -1.4818986 , -0.59343479,  0.9486833 ,\n",
       "        1.08114749,  0.65012832,  0.41768823,  0.71552269,  0.89087584,\n",
       "       -0.96214778,  0.76100977,  1.25437309,  1.10277769,  0.71819384,\n",
       "       -0.40231063, -1.4946982 ,  1.11931722, -2.00298107, -2.43748814,\n",
       "       -0.69148984, -1.27778105,  0.44324371, -0.73352656, -2.21485187,\n",
       "        1.29809898, -2.20839212, -0.36593953,  1.09450837,  0.82295589,\n",
       "        0.63157195,  0.95644972, -1.18861002,  0.55217149, -0.39384837,\n",
       "        0.52111151,  1.13288607, -0.01490193,  1.307993  , -0.65449807,\n",
       "       -0.07539255, -1.91107868, -0.08229376, -0.11010442,  0.93603593])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"bed matrix shape:\", bed.val.shape\n",
    "print \"Size of bed matrix: %4.0fmb\" %(bed.val.nbytes/(1024**2))\n",
    "bed.val[0,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fam file dataset1.fam\n",
      "Loading bim file dataset1.bim\n",
      "bed file is open dataset1.bed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10499"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Bed(bfile)\n",
    "f.sid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(f.read().val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "In both Python 2.7 and Python 3.5 the modules that read the .bed files perpetually keep the .bed file open. The one in Python3.5 can close the connection though, pysnptools can't(at least couldn't find a way).\n",
    "\n",
    "The object 'bed' from Bed(file).read().standardize() has a method bid.sid that enumerates all of the SNPS contained in the file. The equivalent in the plinkio is plinkio.open(file).get_locus() and then each item in locus contains a SNP and the information thereon, including which chromosome it comes from. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposing leap Utils BED processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysnptools.util as pstutil\n",
    "import pysnptools.util.pheno as phenoUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:loadPhen is using default missing value of '-9'.\n"
     ]
    }
   ],
   "source": [
    "pheno = phenoUtils.loadOnePhen('dataset1.phe', missing='-9', vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['FAM1', 'person1'],\n",
       "       ['FAM1', 'person2'],\n",
       "       ['FAM1', 'person3'],\n",
       "       ..., \n",
       "       ['FAM1', 'person998'],\n",
       "       ['FAM1', 'person999'],\n",
       "       ['FAM1', 'person1000']], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno['iid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size of pheno matrix: ', (1000,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of pheno matrix: \",pheno['vals'].shape)\n",
    "np.unique(pheno['vals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-cc691a0fdac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpheno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpstutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpheno\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msid_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "bed, pheno = pstutil.intersect_apply([f, pheno])\n",
    "bed.sid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Apparently, the pheno['iid'] is suppose to match the bed.iid object. When the writers do \"checkIntersection\" they essentially check whether the persons and family of bed and pheno objects match up. If not, it throws an error. I presume this is how the two are matched up. Either way, \"checkIntersection\" doesn't return anything.  I think pstutil.intersect_apply is the function that intersects the two files? Documentation isn't clear either.\n",
    "\n",
    "It seems that plinkio reads in phenotype automatically and the phenotype can be read from the generator items in sample_list. However, it seems that the phenotypes returned by plinkio are approximately normal...which is strange and may be due to our test data file. \n",
    "\n",
    "Information such as family, iid, and the like can also be accessed in a similar fashion as phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loadPhen is using default missing value of '-9'.\n"
     ]
    }
   ],
   "source": [
    "covarsDict = phenoUtils.loadPhen('dataset1.cov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vals', 'header', 'iid']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covarsDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['FAM1', 'person1'],\n",
       "       ['FAM1', 'person2'],\n",
       "       ['FAM1', 'person3'],\n",
       "       ..., \n",
       "       ['FAM1', 'person998'],\n",
       "       ['FAM1', 'person999'],\n",
       "       ['FAM1', 'person1000']], \n",
       "      dtype='|S18')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covarsDict['iid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87259804],\n",
       "       [-0.6069933 ],\n",
       "       [-0.82491783],\n",
       "       [-2.03853838],\n",
       "       [ 1.84707776],\n",
       "       [ 0.03316381],\n",
       "       [-0.72371969],\n",
       "       [-0.80086393],\n",
       "       [ 0.91305371],\n",
       "       [ 0.24719815]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covarsDict['vals'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covars\n",
    "\n",
    "The .cov file is a tab delimited file with three columns: FAM, person, covariance. The loadPhen function just loads the stuff into a dictionary but this could be easily done into a regular pandas. (our goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#related file is apparently generated and then is optionally in. Otherwise it's created from bed\n",
    "#relatedDict = phenoUtils.loadOnePhen(relFile, vectorize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
