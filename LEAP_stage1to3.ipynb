{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plinkio\n",
      "  Downloading plinkio-0.9.6.tar.gz\n",
      "Building wheels for collected packages: plinkio\n",
      "  Running setup.py bdist_wheel for plinkio ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/6f/e2/58/0f2d910f7aa9154227bf313074794f255534879d9f0b66e863\n",
      "Successfully built plinkio\n",
      "Installing collected packages: plinkio\n",
      "Successfully installed plinkio-0.9.6\n"
     ]
    }
   ],
   "source": [
    "!pip install plinkio\n",
    "##Load data:\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plinkio import plinkfile\n",
    "import time\n",
    "#from scipy.linalg.blas import dsyrk \n",
    "    #--can't find a way to get this working. Perhaps blas routines are missing.\n",
    "    \n",
    "data_path = '/home/jovyan/work/LEAP/leap/regression/dataset1'\n",
    "os.chdir(data_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nauthor: gene burinskiy\\n\\nGoal: \\nFinding a set of individuals who are related to other individuals in the study. \\nLEAP employs a greedy algorithm to find a small subset of such individuals, \\nsuch that after their exclusion, there are no related individuals in the study. \\nThese individuals are excluded from the analysis in stages 3 and 4 below, \\nbut after fitting a model in stage 4, their liabilities are estimated along with \\nother indviduals. All individuals are considered in the GWAS stage (stage 5).\\n\\nsource: \\nhttps://github.com/omerwe/LEAP/blob/master/leap/regression/Leap_example.ipynb\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "author: gene burinskiy\n",
    "\n",
    "Goal: \n",
    "Finding a set of individuals who are related to other individuals in the study. \n",
    "LEAP employs a greedy algorithm to find a small subset of such individuals, \n",
    "such that after their exclusion, there are no related individuals in the study. \n",
    "These individuals are excluded from the analysis in stages 3 and 4 below, \n",
    "but after fitting a model in stage 4, their liabilities are estimated along with \n",
    "other indviduals. All individuals are considered in the GWAS stage (stage 5).\n",
    "\n",
    "source: \n",
    "https://github.com/omerwe/LEAP/blob/master/leap/regression/Leap_example.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of locuses 10499\n",
      "# of chromosomes in data: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "Number of individuals in data: 1000\n"
     ]
    }
   ],
   "source": [
    "##Load data:\n",
    "bed = plinkfile.open(\"dataset1\")\n",
    "\n",
    "loci = bed.get_loci()\n",
    "print(\"Length of locuses\", len(loci))\n",
    "chromosomes = np.unique([x.chromosome for x in loci])\n",
    "print(\"# of chromosomes in data:\",chromosomes)\n",
    "\n",
    "samples = bed.get_samples()\n",
    "print(\"Number of individuals in data:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: int16\n",
      "Size of bed matrix:   20mb\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, person1 to person1000\n",
      "Columns: 10499 entries, (1, csnp18) to (10, snp10483)\n",
      "dtypes: int16(10499)\n",
      "memory usage: 20.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>chromosome</th>\n",
       "      <th colspan=\"5\" halign=\"left\">1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snp</th>\n",
       "      <th>csnp18</th>\n",
       "      <th>csnp35</th>\n",
       "      <th>csnp59</th>\n",
       "      <th>csnp78</th>\n",
       "      <th>csnp85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "chromosome      1                            \n",
       "snp        csnp18 csnp35 csnp59 csnp78 csnp85\n",
       "person1         2      1      1      2      1\n",
       "person2         1      0      2      2      2\n",
       "person3         0      2      2      2      2\n",
       "person4         2      1      2      2      1\n",
       "person5         0      1      2      1      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Place data into a dataframe:\n",
    "mat = np.zeros((len(loci),len(samples)), dtype='int16') #1/4 of the taken up space by using int16\n",
    "\n",
    "##don't know a faster method of extracting the data from the bed file.\n",
    "i=0\n",
    "for row in bed:\n",
    "    mat[i,:] = np.array([snp for snp in row])\n",
    "    i+=1\n",
    "    \n",
    "#this matrix is equivalent to transposed bed.val\n",
    "print(\"Data type:\", mat.dtype)\n",
    "print(\"Size of bed matrix: %4.0fmb\\n\" %(mat.nbytes/(1024**2)))\n",
    "\n",
    "#create a multi-indexed column space\n",
    "tuples = [(x.chromosome,x.name) for x in loci]\n",
    "ml_index = pd.MultiIndex.from_tuples(tuples, names = ['chromosome', 'snp'])\n",
    "\n",
    "df = pd.DataFrame(mat.transpose(), columns=ml_index, index = [x.iid for x in bed.get_samples()]) \n",
    "df.info()\n",
    "df.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, person1 to person1000\n",
      "Columns: 10499 entries, (1, csnp18) to (10, snp10483)\n",
      "dtypes: float32(10499)\n",
      "memory usage: 40.1+ MB\n",
      "\n",
      "Covariance shape: (1000, 1000)\n",
      "Covariance memory usage in mb: 3.814697265625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.36813205,  0.00128837, -0.00865505, -0.00119463,  0.00389233],\n",
       "       [ 0.00128837,  0.35822782,  0.00339448,  0.00228265,  0.00136904],\n",
       "       [-0.00865505,  0.00339448,  0.36281955,  0.00443562, -0.00057362],\n",
       "       [-0.00119463,  0.00228265,  0.00443562,  0.3630724 ,  0.0018387 ],\n",
       "       [ 0.00389233,  0.00136904, -0.00057362,  0.0018387 ,  0.37096035]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##compute covariance matrix between individuals, remove those who are too close to each other.\n",
    "#they LEAP code uses dsyrk which halves the computational time. Alas, we can't use it y\n",
    "\n",
    "df = df.astype('float32')-df.astype('float32').mean() \n",
    "df.info() #roughly doubled memory usage though still not the 80mb it was earlier\n",
    "\n",
    "cov = np.dot(df, df.transpose())/df.shape[1] #having difficulties with scipy's linalg module\n",
    "#note that the above takes more than half the time of np.cov\n",
    "print(\"\\nCovariance shape:\" , cov.shape)\n",
    "print(\"Covariance memory usage in mb:\", cov.nbytes/(1024**2))\n",
    "cov[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y: (56,)\n",
      "\n",
      "removing 56 individuals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(953,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = .05\n",
    "bool_arr =  np.tril(cov, k=-1)>cutoff\n",
    "y_idx,_ = np.where(bool_arr)\n",
    "print(\"shape of y:\", y_idx.shape)\n",
    "print(\"\\nremoving %d individuals\" %y_idx.shape[0])\n",
    "\n",
    "#note, they marked 54 so we marked more peeps, we effectively remove 47. Something doesn't line up.\n",
    "indxToKeep = set(range(cov.shape[0]))\n",
    "[indxToKeep.remove(i) for i in np.unique(y_idx)]\n",
    "keepArr = np.array(list(indxToKeep))\n",
    "keepArr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 4}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_set = set(range(5))\n",
    "[t_set.remove(i) for i in [2,3]]\n",
    "t_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.6601\n",
      "14.6601\n"
     ]
    }
   ],
   "source": [
    "#exploring different ways to exclude individuals found above.\n",
    "cov_m = np.ma.array(cov,mask=False)\n",
    "cov_m.mask[y_idx,:] = True\n",
    "cov_m.mask[:,x_idx] = True\n",
    "\n",
    "print(cov_m.sum())\n",
    "\n",
    "cov_c = np.delete(np.delete(cov, y_idx, axis=0), x_idx, axis=1)\n",
    "print(cov_c.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 934)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying to match the authors' results but uh, to no avail.\n",
    "corr = np.corrcoef(df)\n",
    "bool_arr =  np.tril(corr, k=-1)>cutoff\n",
    "y_idx,x_idx = np.where(bool_arr)\n",
    "\n",
    "corr_c = np.delete(np.delete(corr, y_idx, axis=0), x_idx, axis=1)\n",
    "corr_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on chromosome: 1\n",
      "Took 0.30 seconds\n",
      "Working on chromosome: 2\n",
      "Took 0.21 seconds\n",
      "Working on chromosome: 3\n",
      "Took 0.21 seconds\n",
      "Working on chromosome: 4\n",
      "Took 0.19 seconds\n",
      "Working on chromosome: 5\n",
      "Took 0.18 seconds\n",
      "Working on chromosome: 6\n",
      "Took 0.18 seconds\n",
      "Working on chromosome: 7\n",
      "Took 0.29 seconds\n",
      "Working on chromosome: 8\n",
      "Took 0.25 seconds\n",
      "Working on chromosome: 9\n",
      "Took 0.20 seconds\n",
      "Working on chromosome: 10\n",
      "Took 0.20 seconds\n",
      "Note that LEAP's original code runs 2-3 times slower for this step\n"
     ]
    }
   ],
   "source": [
    "#with multi-index, we index by using the number of the chromosome. \n",
    "#This avoids copying of data -> we use views on the data. Immeasurably more efficient\n",
    "for chrom in chromosomes:\n",
    "    print(\"Working on chromosome: %s\" %chrom)\n",
    "    \n",
    "    exclude_chrom = set(chromosomes)\n",
    "    exclude_chrom.remove(chrom) #set all chromosomes except current\n",
    "    exclude_chrom = list(exclude_chrom)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    #Note that the original code puts cov, s, U into a dictionary called \"eigen\"\n",
    "    #They do not actually perform an SVD decomposition. Instead, they compute\n",
    "    #the covariance matrix, decompose that and use an equivalence relation between\n",
    "    #SVD and the decomposition of the covariance matrix. However, it seems that a \n",
    "    #set could be saved if they just performed the SVD decomposition, albeit at a higher computing cost\n",
    "    cov = np.dot(df[exclude_chrom], df[exclude_chrom].transpose())/df[exclude_chrom].shape[1]\n",
    "    \n",
    "    s,U = np.linalg.eigh(cov, 'L') #would use scipy except -again- can't get it to load.\n",
    "    \n",
    "    print(\"Took %.2f seconds\" %(time.time()-t0))\n",
    "print(\"Note that LEAP's original code runs 2-3 times slower for this step\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fam</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person1</th>\n",
       "      <td>FAM1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person2</th>\n",
       "      <td>FAM1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person3</th>\n",
       "      <td>FAM1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person4</th>\n",
       "      <td>FAM1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person5</th>\n",
       "      <td>FAM1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fam  pheno\n",
       "person              \n",
       "person1  FAM1      0\n",
       "person2  FAM1      0\n",
       "person3  FAM1      0\n",
       "person4  FAM1      0\n",
       "person5  FAM1      0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Our calc_h2 function for Step 3\n",
    "#uses the calc_h2.calc_h2 functions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "#read in phenofile:\n",
    "phenos = pd.read_csv(\"dataset1.phe\", sep=' ', header=None, engine='c')\n",
    "phenos.columns = ['fam', 'person', 'pheno']\n",
    "phenos.set_index(keys = 'person', inplace=True)\n",
    "phenos.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#another part of the calc_h2 function\n",
    "prev, prevalence = [.001]*2\n",
    "\n",
    "numRemovePCs=10 #their default value; as far as I'm aware, they do not input different values\n",
    "\n",
    "if numRemovePCs>0:\n",
    "    t_cov = cov -  (U[:,-numRemovePCs:]*s[-numRemovePCs:]).dot(U[:,-numRemovePCs:].transpose())\n",
    "        \n",
    "pheUnique = phenos.pheno.unique()\n",
    "isCaseControl = pheUnique.shape[0] == 2 #trivial condition for us\n",
    "\n",
    "if ~np.all(pheUnique == np.array([0,1])):\n",
    "    pheMean = phenos.pheno.mean()\n",
    "    phenos.pheno[phenos.pheno <= pheMean] = 0\n",
    "    phenos.pheno[phenoes.pheno > pheMean] = 1\n",
    "    \n",
    "#probs, thresholds = calcLiabThreholds(U, S, keepArr, phe, numRemovePCs, prevalence, covar) \n",
    "\n",
    "#This is equivalent to an SVD decomposition; note their covar parameter is defaulted to None\n",
    "G = U[:, -numRemovePCs:] * np.sqrt(s[-numRemovePCs:])\n",
    "\n",
    "#perform a regularized logistic regression. I trust their parameter settings.\n",
    "Logreg = LogisticRegression(penalty='l2', C=500000, fit_intercept=True)\n",
    "Logreg.fit(G[keepArr, :], phenos.pheno.iloc[keepArr])\n",
    "\n",
    "#Compute individual thresholds\n",
    "probs = Logreg.predict_proba(G)[:,1]\n",
    "\n",
    "#Compute thresholds\n",
    "P = np.sum(phenos.pheno==1) / float(phenos.pheno.shape[0])\n",
    "#K = prev --why, why in the (insert explicative) hell do they do this?\n",
    "Ki = prev*(1-prev) / (P*(1-prev)) * probs / (1 + prev*(1-prev) / (P*(1-prev))*probs - probs)\n",
    "thresholds = stats.norm(0,1).isf(Ki)\n",
    "thresholds[Ki>=1.] = -999999999\n",
    "thresholds[Ki<=0.] = 999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#h2 = calcH2Binary(XXT, phe, probs, thresholds, keepArr, prevalence, h2coeff)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 154 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.dot(df, df.transpose())/df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 354 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.cov(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
